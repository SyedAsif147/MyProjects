{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset\n",
    "dataset=pd.read_csv('D:/datasets/heart.csv')\n",
    "X = dataset.iloc[:,0:13].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting dataset into training set and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Syed\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#using various classifiers\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "cm1=confusion_matrix(y_test,y_pred)\n",
    "lr_acc=accuracy_score(y_test,y_pred)\n",
    "lr_prec=cm1[1][1]/(cm1[1][1]+cm1[0][1])\n",
    "lr_recall=cm1[1][1]/(cm1[1][1]+cm1[1][0])\n",
    "lr_f1=2*lr_prec*lr_recall/(lr_prec+lr_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# KNN Classifier using k=10\n",
    "knn=KNeighborsClassifier(n_neighbors = 10, metric = 'minkowski', p=2)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "knn_acc=accuracy_score(y_test,y_pred)\n",
    "cm2=confusion_matrix(y_test,y_pred)\n",
    "knn_prec=cm2[1][1]/(cm2[1][1]+cm2[0][1])\n",
    "knn_recall=cm2[1][1]/(cm2[1][1]+cm2[1][0])\n",
    "knn_f1=2*knn_prec*knn_recall/(knn_prec+knn_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC Gaussian\n",
    "from sklearn.svm import SVC\n",
    "svc1=SVC(kernel='rbf')\n",
    "svc1.fit(X_train,y_train)\n",
    "y_pred=svc1.predict(X_test)\n",
    "svc_acc=accuracy_score(y_test,y_pred)\n",
    "cm3=confusion_matrix(y_test,y_pred)\n",
    "svc_prec=cm3[1][1]/(cm3[1][1]+cm3[0][1])\n",
    "svc_recall=cm3[1][1]/(cm3[1][1]+cm3[1][0])\n",
    "svc_f1=2*svc_prec*svc_recall/(svc_prec+svc_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC Linear\n",
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel='linear')\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred=svc.predict(X_test)\n",
    "svc_lin_acc=accuracy_score(y_test,y_pred)\n",
    "cm5=confusion_matrix(y_test,y_pred)\n",
    "svc_lin_prec=cm5[1][1]/(cm5[1][1]+cm5[0][1])\n",
    "svc_lin_recall=cm5[1][1]/(cm5[1][1]+cm5[1][0])\n",
    "svc_lin_f1=2*svc_lin_prec*svc_lin_recall/(svc_lin_prec+svc_lin_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier(criterion = 'entropy', max_depth=7, random_state=0)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "dec_acc=accuracy_score(y_test, y_pred)\n",
    "cm6=confusion_matrix(y_test,y_pred)\n",
    "dec_prec=cm6[1][1]/(cm6[1][1]+cm6[0][1])\n",
    "dec_recall=cm6[1][1]/(cm6[1][1]+cm6[1][0])\n",
    "dec_f1=2*dec_prec*dec_recall/(dec_prec+dec_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Decision trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier(n_estimators=100, criterion = 'entropy', random_state=0)\n",
    "rfc.fit(X_train,y_train)\n",
    "y_pred=rfc.predict(X_test)\n",
    "rfc_acc=accuracy_score(y_test,y_pred)\n",
    "cm7=confusion_matrix(y_test,y_pred)\n",
    "rfc_prec=cm7[1][1]/(cm7[1][1]+cm7[0][1])\n",
    "rfc_recall=cm7[1][1]/(cm7[1][1]+cm7[1][0])\n",
    "rfc_f1=2*rfc_prec*rfc_recall/(rfc_prec+rfc_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Syed\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 2 - 1) = 1 components.\n",
      "  ChangedBehaviorWarning)\n",
      "C:\\Users\\Syed\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n",
      "C:\\Users\\Syed\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:466: ChangedBehaviorWarning: n_components cannot be larger than min(n_features, n_classes - 1). Using min(n_features, n_classes - 1) = min(13, 2 - 1) = 1 components.\n",
      "  ChangedBehaviorWarning)\n",
      "C:\\Users\\Syed\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:472: FutureWarning: In version 0.23, setting n_components > min(n_features, n_classes - 1) will raise a ValueError. You should set n_components to None (default), or a value smaller or equal to min(n_features, n_classes - 1).\n",
      "  warnings.warn(future_msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Dimensionality Reduction\n",
    "# Applying LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda=LDA(n_components = 2)\n",
    "X_train = lda.fit_transform(X_train,y_train)\n",
    "X_test = lda.fit_transform(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb=GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred=gnb.predict(X_test)\n",
    "gnb_acc=accuracy_score(y_test,y_pred)\n",
    "cm4=confusion_matrix(y_test,y_pred)\n",
    "gnb_prec=cm4[1][1]/(cm4[1][1]+cm4[0][1])\n",
    "gnb_recall=cm4[1][1]/(cm4[1][1]+cm4[1][0])\n",
    "gnb_f1=2*gnb_prec*gnb_recall/(gnb_prec+gnb_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LDA + Naive Bayes</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.925373</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.885246</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>RBF SVC</td>\n",
       "      <td>0.868852</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy Score  Precision    Recall  F1 Score  TP  TN\n",
       "2    LDA + Naive Bayes        0.918033   0.939394  0.911765  0.925373  25  31\n",
       "0                  KNN        0.885246   0.909091  0.882353  0.895522  24  30\n",
       "6              RBF SVC        0.868852   0.842105  0.941176  0.888889  21  32\n",
       "1  Logistic Regression        0.836066   0.833333  0.882353  0.857143  21  30\n",
       "3        Random Forest        0.819672   0.848485  0.823529  0.835821  22  28\n",
       "5           Linear SVC        0.819672   0.810811  0.882353  0.845070  20  30\n",
       "4        Decision Tree        0.786885   0.862069  0.735294  0.793651  23  25"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the prec,recall,f1 table\n",
    "models=pd.DataFrame({\n",
    "    'Model' : ['KNN','Logistic Regression','LDA + Naive Bayes','Random Forest','Decision Tree','Linear SVC','RBF SVC'],\n",
    "    'Accuracy Score' : [knn_acc,lr_acc,gnb_acc,rfc_acc,dec_acc,svc_lin_acc,svc_acc],\n",
    "    'Precision' : [knn_prec,lr_prec,gnb_prec,rfc_prec,dec_prec,svc_lin_prec,svc_prec],\n",
    "    'Recall' : [knn_recall,lr_recall,gnb_recall,rfc_recall,dec_recall,svc_lin_recall,svc_recall],\n",
    "    'F1 Score' : [knn_f1,lr_f1,gnb_f1,rfc_f1,dec_f1,svc_lin_f1,svc_f1],\n",
    "    'TP' : [cm2[0][0],cm1[0][0],cm4[0][0],cm7[0][0],cm6[0][0],cm5[0][0],cm3[0][0]],\n",
    "    'TN' : [cm2[1][1],cm1[1][1],cm4[1][1],cm7[1][1],cm6[1][1],cm5[1][1],cm3[1][1]]\n",
    "})\n",
    "models.sort_values(by='Accuracy Score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models.to_csv(r\"C:\\Users\\Syed\\Desktop\\Project_files\\dataset_folder\\heart_data_out.csv\",index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
